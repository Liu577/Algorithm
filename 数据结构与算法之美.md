# 数据结构与算法

## 一、入门篇

### 1.1 大O复杂度表示法

#### 时间复杂度分析

0. 大 O 时间复杂度实际上并不具体表示代码真正的执行时间，而是表示代码执行时间随数据规模增长的变化趋势，所以，也叫作渐进时间复杂度（asymptotic time complexity），简称时间复杂度。

1. 只关注循环执行次数最多的一段代码。
2. 加法法则：总复杂度等于量级最大的那段代码的复杂度。
3. 乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积。

#### 几种常见时间复杂度实例分析

1. 多项式量级：O（2^n）、O（n！）
2. 非多项式量级：O（1）、O（logn）、O（n）、O（nlogn）O（n^k）

#### 空间复杂度分析

空间复杂度全称就是渐进空间复杂度。

### 1.2 四个复杂度概念

#### 最好、最坏时间复杂度

最好情况时间复杂度就是，在最理想的情况下，执行这段代码的时间复杂度。

最坏情况时间复杂度就是，在最糟糕的情况下，执行这段代码的时间复杂度。

#### 平均时间复杂度

平均时间复杂度的全称应该叫加权平均时间复杂度或者期望时间复杂度。

#### 均摊时间复杂度

通过摊还分析得到的时间复杂度，叫均摊时间复杂度。

## 二、基础篇

### 2.1 数组（Array）

数组是一种**线性表**数据结构。它用一组**连续的内存空间**，来存储一组具有相同类型的数据，支持随机访问。

插入和删除效率低

### 2.2 链表（Linked list）

链表通过指针将一组零散的内存块串联在一起。其中，我们把内存块称为链表的“结点”。

#### 单链表、循环链表和双向链表。

单链表的尾结点指针指向空地址，而循环链表的尾结点指针是指向链表的头结点，循环链表是一种特殊的单链表。

单向链表只有一个方向，结点只有一个后继指针 next 指向后面的结点。而双向链表，它支持两个方向，除了后继指针 next ，还有一个前驱指针 prev 指向前面的结点。

#### 基于链表实现 LRU 缓存淘汰算法

维护一个有序单链表，越靠近链表尾部的结点是越早之前访问的。当有一个新的数据被访问时，我们从链表头开始顺序遍历链表。

1. 如果此数据之前已经被缓存在链表中了，我们遍历得到这个数据对应的结点，并将其从原来的位置删除，然后再插入到链表的头部。

2.  如果此数据没有在缓存链表中，又可以分为两种情况：

   如果此时缓存未满，则将此结点直接插入到链表的头部；

   如果此时缓存已满，则链表尾结点删除，将新的数据结点插入链表的头部。

#### 如何写好链表代码

1. 理解指针和引用的概念

2. 警惕指针丢失和内存泄漏

3. 利用哨兵简化

4. 重点留意边界条件处理

   链表为空、链表只包含一个结点、链表只包含两个结点、处理头结点和尾结点

### 2.3 栈（Stack）

#### 基本概念 

定义：从操作特性上来看，栈是一种“操作受限”的线性表，只允许在一端插入和删除数据。

特征：后进者先出，先进者后出。

主要操作：入栈、出栈。

实现：顺序栈、链式栈。

#### 栈的应用

1. 函数调用
2. 表达式求值
3. 括号匹配
4. 浏览器回退

### 2.4 队列（Queue）

#### 基本概念

定义：是一种操作受限的线性表数据结构，一端只能进入，一端只能移出。

特征：先进先出，后进后出。

主要操作：入队、出队。

类型：顺序队列、链式队列、循环队列、阻塞队列、并发队列

### 2.5 递归（Recursion）

#### 基本概念

去的过程为递，回来的过程叫归，关键是求出递推公式，找到终止条件。

#### 三个必要条件：

1. 一个问题的解可以分解为几个子问题的解
2. 这个问题与分解之后的子问题，除了数据规模不同，求解思路完全一样
3. 存在递归终止条件

#### 递归技巧

1. 把它抽象成一个递推公式，不用想一层层的调用关系，不要试图用人脑去分解递归的每个步骤。
2. 警惕堆栈溢出
3. 警惕重复计算

### 2.6 排序（Sort）

#### 基本概念

##### 排序算法的执行效率

1. 最好情况、最坏情况、平均情况时间复杂度

2. 时间复杂度的系数、常数、低阶

   对同一阶时间复杂度的排序算法性能对比的时候，我们要把系数、常数、低阶也考虑进来。

3.  比较次数和交换（或移动）次数

##### 排序算法的内存消耗

原地排序算法，特指空间复杂度是 O(1) 的排序算法。

##### 排序算法的稳定性

稳定排序算法可以保持金额相同的两个对象，在排序之后的前后顺序不变。

##### 有序度和逆序度

有序度是数组中具有有序关系的元素对的个数，逆序度是数组中不具有有序关系的元素对的个数，

一个完全有序的数组的有序度叫做满有序度，n个元素的数组满有序度是n*(n-1)/2。

#### 冒泡、插入、选择排序

| 排序方法 | 时间复杂度 | 空间复杂度 | 是否基于比较 | 是否稳定 |
| -------- | ---------- | ---------- | ------------ | -------- |
| 冒泡排序 | O（n^2）   | O（1）     | 是           | 是       |
| 插入排序 | O（n^2）   | O（1）     | 是           | 是       |
| 选择排序 | O（n^2）   | O（1）     | 是           | 否       |

##### 冒泡排序（Bubble sort）

冒泡排序只会操作相邻的两个数据。每次冒泡操作都会对相邻的两个元素进行比较，看是否满足大小关系要求。如果不满足就让它俩互换。

##### 插入排序（Insertion Sort）

插入排序将数组中的数据分为已排序区间和未排序区间。初始已排序区间只有一个元素，就是数组的第一个元素。取未排序区间中的元素，在已排序区间中找到合适的插入位置将其插入，并保证已排序区间数据一直有序。

##### 选择排序（Selection Sort）

选择排序将数组中的数据分为已排序区间和未排序区间。取未排序区间中找到最小的元素，将其放到已排序区间的末尾。

#### 归并排序和快速排序

| 排序方法 | 时间复杂度 | 空间复杂度 | 是否基于比较 | 是否稳定 |
| -------- | ---------- | ---------- | ------------ | -------- |
| 归并排序 | O(nlogn)   | O(n)       | 是           | 是       |
| 快速排序 | O(nlogn)   | O(1)       | 是           | 否       |

##### 归并排序（Merge Sort）

归并排序把数组从中间分成前后两部分，然后对前后两部分分别排序，再将排好序的两部分合并在一起，即分治思想。分治算法一般都是用递归来实现的，分治是一种解决问题的处理思想，递归是一种编程技巧。

##### 快速排序（Quick Sort）

快速排序是选择数组之间的任意一个数据作为 pivot（分区点），遍历数组，将小于 pivot 的放到左边，将大于 pivot 的放到右边，将 pivot 放到中间。快速排序同样用到了分治思想。

##### 快排和归并的区别

归并排序的处理过程是由下到上的，先处理子问题，然后再合并。而快排正好相反，它的处理过程是由上到下的，先分区，然后再处理子问题。

#### 线性排序（Linear sort）

| 排序方法 | 时间复杂度 | 空间复杂度 | 是否基于比较 | 是否稳定 |
| -------- | ---------- | ---------- | ------------ | -------- |
| 桶排序   | O（n）     | O（n）     | 否           | 是       |
| 计数排序 | O（n+k）   | O（n）     | 否           | 是       |
| 基数排序 | O（dn）    | O（n）     | 否           | 是       |

##### 桶排序（Bucket sort）

桶排序是将要排序的数据分到几个有序的桶里，每个桶里的数据再单独进行排序。桶内排完序之后，再把每个桶里的数据按照顺序依次取出，组成序列。

##### 计数排序（Counting sort）

计数排序其实是桶排序的一种特殊情况。当要排序的 n 个数据，所处的范围并不大的时候，比如最大值是 k，就可以把数据划分成 k 个桶。每个桶内的数据值都是相同的，省掉了桶内排序的时间。

##### 基数排序（Radix sort）

对于位数太大的数据，使用稳定的线性排序算法逐位进行排序，位数不足时补0。但每一位的数据范围不能太大，否则无法使用线性排序算法。

#### 实现一个通用的、高性能的排序函数

##### 选用原则

1. 不能选择线性排序算法
2. 首选时间复杂度是 O(nlogn) 的排序算法
3. 根据情况选择空间复杂度

##### 优化快速排序

1. 选择合理的分区点，最理想的分区点是被分区点分开的两个分区中，数据的数量差不多。常用的简单分区算法有三（多）数取中法、随机法

2. 警惕堆栈溢出，可以用限制递归深度和手动在堆上模拟函数调用栈的方法。

##### qsort（）算法举例

1. 数据量较小时采用归并排序

2. 数据量较大时采用快速排序
3. 分区方法使用三数取中法
4. 快速排序递归到元素小于等于4时，退化为插入排序

### 2.7 二分查找（Binary Search）

##### 基本概念

时间复杂度O（logn）

二分查找针对的是一个有序的数据集合，类似分治思想，每次都通过跟区间的中间元素对比，将待查找的区间缩小为之前的一半，直到找到要查找的元素，或者区间被缩小为 0。

##### 二分查找的难点

1. 循环退出条件
2. mid 的取值
3. low 和 high 的更新

##### 二分查找的递归实现

```
// 二分查找的递归实现
public int bsearch(int[] a, int n, int val) {
  return bsearchInternally(a, 0, n - 1, val);
}

private int bsearchInternally(int[] a, int low, int high, int value) {
  if (low > high) return -1;

  int mid =  low + ((high - low) >> 1);
  if (a[mid] == value) {
    return mid;
  } else if (a[mid] < value) {
    return bsearchInternally(a, mid+1, high, value);
  } else {
    return bsearchInternally(a, low, mid-1, value);
  }
}
```

##### 二分查找应用场景的局限性

1. 二分查找依赖的是顺序表结构，简单点说就是数组。
2. 二分查找针对的是有序数据。
3. 数据量太小不适合二分查找。
4. 数据量太大也不适合二分查找。

##### 二分查找的变形

1. 查找第一个值等于给定值的元素
2. 查找最后一个值等于给定值的元素
3. 查找第一个大于等于给定值的元素
4. 查找最后一个小于等于给定值的元素

### 2.8 跳表（Skip list）

##### 基本概念

空间复杂度O（n）查找时间复杂度O（logn）

跳表是链表的一种改进，是一种各方面性能都比较优秀的动态数据结构，可以支持快速地插入、删除、查找操作，写起来也不复杂，甚至可以替代红黑树（Red-black tree）。

##### 跳表的实现

对链表建立多级索引，每两个结点提取一个索引结点到上级。按照索引进行查找，需要遍历的结点就变少了，当链表的长度 n 比较大时，在构建索引之后，查找效率的提升就会非常明显。

链表是一种典型的空间换时间的实现。在实际的软件开发中，原始链表中存储的有可能是很大的对象，而索引结点只需要存储关键值和几个指针，并不需要存储对象，所以当对象比索引结点大很多时，那索引占用的额外空间就可以忽略了。

##### 高效的动态插入和删除

插入时间复杂度O（logn）

删除时间复杂度O（logn）可以用双向链表解决前驱结点的获取问题

##### 跳表索引动态更新

当不停地往跳表中插入数据时，如果我们不更新索引，就有可能出现某 2 个索引结点之间数据非常多的情况。极端情况下，跳表还会退化成单链表。

跳表是通过随机函数来维护平衡性，通过一个随机函数，来决定将这个结点插入到哪几级索引中，比如随机函数生成了值 K，就将这个结点添加到第一级到第 K 级这 K 级索引中。

### 2.9 散列表（Hash Table）

#### 散列思想

散列表是数组的一种扩展，由数组演化而来，核心是散列函数的设计和散列冲突的解决。

键（key）或者关键字，通过散列函数（或“Hash 函数”“哈希函数”）计算得到的值就叫作散列值（或“Hash 值”“哈希值”）。

#### 散列函数

散列函数设计的基本要求

1. 散列函数计算得到的散列值是一个非负整数
2. 如果 key1 = key2，那 hash(key1) == hash(key2)；
3. 如果 key1 ≠ key2，那 hash(key1) ≠ hash(key2)。

#### 散列冲突

##### 起因

在真实的情况下，要想找到一个不同的 key 对应的散列值都不一样的散列函数，几乎是不可能的，所以散列冲突无法完全避免。而且，因为数组的存储空间有限，也会加大散列冲突的概率。

##### 解决办法

1. 开放寻址法（open addressing）

   1）线性探测（Linear Probing）：如果某个数据经过散列函数散列之后，存储位置已经被占用了，我们就从当前位置开始，依次往后查找，看是否有空闲位置，直到找到为止。但当散列表中插入的数据越来越多时，散列冲突发生的可能性就会越来越大，空闲位置会越来越少，线性探测的时间就会越来越久，最差时间复杂度为**O（n）**。

   2）二次探测（Quadratic probing）：跟线性探测很像，但二次探测探测的步长为上一次步长的“二次方”。

   3）双重散列（Double hashing）：我们先用第一个散列函数，如果计算得到的存储位置已经被占用，再用第二个散列函数，依次类推，直到找到空闲的存储位置。

   4）在开放寻址法中，**删除操作实际上将删除的值标记**，而不是实际删除。

   5）不管采用哪种探测方法，当散列表中空闲位置不多的时候，散列冲突的概率就会大大提高。为了尽可能保证散列表的操作效率，一般情况下，我们会尽可能保证散列表中有一定比例的空闲槽位。我们用装载因子（load factor）来表示空位的多少。**列表的装载因子=填入表中的元素个数/散列表的长度。**装载因子越大，说明空闲位置越少，冲突越多，散列表的性能会下降。

   6）当数据量比较小、装载因子小的时候，适合采用开放寻址法。

2. 链表法（chaining）

   1）链表法是一种更加常用的散列冲突解决办法，相比开放寻址法，它要简单很多。散列表中，每个“桶（bucket）”或者“槽（slot）”会对应一条链表，所有散列值相同的元素我们都放到相同槽位对应的链表中。

   2）链表法插入的时间复杂度为O（1），查找和删除的时间复杂度为O（k），k为链表长度，理论上k=n/m，n为散列中数据的个数，m为“桶（bucket）”或者“槽（slot）”的个数。

   3）链表法对内存的利用率比开放寻址法要高，适合存储大对象、大数据量的散列表，而且，比起开放寻址法，它更加灵活，支持更多的优化策略，比如用红黑树代替链表。

#### 散列表的设计

##### 设计需求

避免散列冲突时散列表的性能急剧下降，抵抗散列碰撞攻击。

##### 散列函数的设计

1. 散列函数的设计不能太复杂。过于复杂的散列函数，势必会消耗很多计算时间，也就间接地影响到散列表的性能。
2. 散列函数生成的值要尽可能随机并且均匀分布，这样才能避免或者最小化散列冲突，而且即便出现冲突，散列到每个槽里的数据也会比较平均，不会出现某个槽内数据特别多的情况。
3. 考虑实际因素，如关键字的长度，特点，分布，散列表大小等。
4. 举例：直接寻址法、平方取中法、折叠法、随机数法等。

##### 装载因子过大的处理

对于动态散列表来说，数据集合是频繁变动的，我们事先无法预估将要加入的数据个数，所以我们也无法事先申请一个足够大的散列表。随着数据慢慢加入，装载因子就会慢慢变大。当装载因子大到一定程度之后，散列冲突就会变得不可接受。

可以使用动态扩容法对散列表进行扩容，但需要合理的设置装载因子阈值。在这种方法中，散列表的大小变了，数据的存储位置也变了，所以我们需要通过散列函数重新计算每个数据的存储位置。

##### 避免低效的扩容

为了解决一次性扩容耗时过多的情况，可以将扩容操作穿插在插入操作的过程中，分批完成。当装载因子触达阈值之后，我们只申请新空间，但并不将老的数据搬移到新散列表中。当有新数据要插入时，我们将新数据插入新散列表中，并且从老的散列表中拿出一个数据放入到新散列表。每次插入一个数据到散列表，我们都重复上面的过程。经过多次插入操作之后，老的散列表中的数据就一点一点全部搬移到新散列表中了。

#### 散列表和链表的混合使用

##### LRU淘汰算法

1. 基于链表实现

   维护一个按照访问时间从大到小有序排列的链表结构。因为缓存大小有限，当缓存空间不够，需要淘汰一个数据的时候，我们就直接将链表头部的结点删除。当要缓存某个数据的时候，先在链表中查找这个数据。如果没有找到，则直接将数据放到链表的尾部；如果找到了，我们就把它移动到链表的尾部。因为查找数据需要遍历链表，所以单纯用链表实现的 LRU 缓存淘汰算法的时间复杂很高，是 O(n)。

2. 基于链表和散列表的混合实现

   我们使用双向链表存储数据，链表中的每个结点处理存储数据（data）、前驱指针（prev）、后继指针（next）之外，还新增了一个特殊的字段 hnext。因为我们的散列表是通过链表法解决散列冲突的，所以每个结点会在两条链中。一个链是刚刚我们提到的双向链表，另一个链是散列表中的拉链。前驱和后继指针是为了将结点串在双向链表中，hnext 指针是为了将结点串在散列表的拉链中。

   通过散列表对结点进行查找，时间复杂度为O（1），删除时间复杂度同查找。

   而插入稍微复杂一点，需要先查找数据是否在缓存中，如已经存在则直接移到链表尾部，如不存在则先删除链表头部，再将数据插入链表尾部。

##### Redis有序集合

在有序集合中，每个成员对象有两个重要的属性，key（键值）和 score（分值）。

如果我们仅仅按照分值将成员对象组织成跳表的结构，那按照键值来删除、查询成员对象就会很慢，解决方法与 LRU 缓存淘汰算法的解决方法类似。我们可以再按照键值构建一个散列表，这样按照 key 来删除、查找一个成员对象的时间复杂度就变成了 O(1)。同时，借助跳表结构，其他操作也非常高效。

##### Java LinkedHashMap

LinkedHashMap 也是通过散列表和链表组合在一起实现的。它不仅支持按照插入顺序遍历数据，还支持按照访问顺序来遍历数据。按照访问时间排序的 LinkedHashMap 本身就是一个支持 LRU 缓存淘汰策略的缓存系统。

### 2.10 哈希算法（Hash Algorithm）

#### 基本概念

将任意长度的二进制值串映射为固定长度的二进制值串，这个映射的规则就是哈希算法，而通过原始数据映射之后得到的二进制值串就是哈希值。

##### 哈希算法的要求

1. 从哈希值不能反向推导出原始数据（所以哈希算法也叫单向哈希算法）。
2. 对输入数据非常敏感，哪怕原始数据只修改了一个 Bit，最后得到的哈希值也大不相同。
3. 散列冲突的概率要很小，对于不同的原始数据，哈希值相同的概率非常小。
4. 哈希算法的执行效率要尽量高效，针对较长的文本，也能快速地计算出哈希值。

##### 哈希碰撞不能避免的原因

1. 基于组合数学中一个非常基础的理论，鸽巢原理（也叫抽屉原理）。这个原理本身很简单，它是说，如果有 10 个鸽巢，有 11 只鸽子，那肯定有 1 个鸽巢中的鸽子数量多于 1 个，换句话说就是，肯定有 2 只鸽子在 1 个鸽巢内。

2. 哈希算法产生的哈希值的长度是固定且有限的。比如前面举的 MD5 的例子，哈希值是固定的 128 位二进制串，能表示的数据是有限的，最多能表示 2^128 个数据，而我们要哈希的数据是无穷的。

3. 基于鸽巢原理，如果我们对 2^128+1 个数据求哈希值，就必然会存在哈希值相同的情况。

4. 一般情况下，哈希值越长的哈希算法，散列冲突的概率越低。

#### 哈希算法的应用

##### 安全加密

最常使用的加密哈希算法

1. MD5（MD5 Message-Digest Algorithm，MD5 消息摘要算法）
2.  SHA（Secure Hash Algorithm，安全散列算法）
3. DES（Data Encryption Standard，数据加密标准）
4. AES（Advanced Encryption Standard，高级加密标准）

##### 唯一标识

将每个元素经过哈希算法得到的唯一标识存储在散列中，当要查看某个元素是不是存在的时候，我们先通过哈希算法对元素取唯一标识，然后在散列表中查找是否存在这个唯一标识。

##### 数据校验

在BT 协议中，可以通过哈希算法，对 100 个文件块分别取哈希值，并且保存在种子文件中。哈希算法有一个特点，对数据很敏感。只要文件块的内容有一丁点儿的改变，最后计算出的哈希值就会完全不同。当文件块下载完成之后，我们可以通过相同的哈希算法，对下载好的文件块逐一求哈希值，然后跟种子文件中保存的哈希值比对。

##### 散列函数

1. 散列函数是设计一个散列表的关键。它直接决定了散列冲突的概率和散列表的性能。

2. 相对哈希算法的其他应用，散列函数对于散列算法冲突的要求要低很多。即便出现个别散列冲突，只要不是过于严重，我们都可以通过开放寻址法或者链表法解决。

3. 散列函数对于散列算法计算得到的值，是否能反向解密也并不关心。散列函数中用到的散列算法，更加关注散列后的值是否能平均分布，也就是，一组数据是否能均匀地散列在各个槽中。

4. 散列函数执行的快慢，也会影响散列表的性能，所以，散列函数用的散列算法一般都比较简单，比较追求效率。

##### 均衡负载

负载均衡算法有很多，比如轮询、随机、加权轮询等。通过哈希算法可以实现一个会话粘滞（session sticky）的负载均衡算法

##### 数据分片

对于海量数据的处理，可以先对数据进行分片，再将数据中的元素通过哈希算法获得哈希值，将哈希值取模后分配进行处理的机器。

##### 分布式存储

可以借用前面数据分片的思想，即通过哈希算法对数据取哈希值，将哈希值取模后分配进行处理的机器。

但如果需要对服务器进行扩容，所有的数据都要重新计算哈希值，然后重新搬移到正确的机器上。这样就相当于，缓存中的数据一下子就都失效了。所有的数据请求都会穿透缓存，直接去请求数据库。这样就可能发生雪崩效应，压垮数据库。这个时候，需要**一致性哈希算法**。

假设我们有 k 个机器，数据的哈希值的范围是[0, MAX]。我们将整个范围划分成 m 个小区间（m 远大于 k），每个机器负责 m/k 个小区间。当有新机器加入的时候，我们就将某几个小区间的数据，从原来的机器中搬移到新的机器中。这样，既不用全部重新哈希、搬移数据，也保持了各个机器上数据数量的均衡。

##### 其他应用

网络协议中的 CRC 校验、Git commit id等

### 2.11 二叉树（Binary Tree）

#### 基本概念

树是一种非线性表结构。

##### 树（Tree）

关键词：父节点、子节点、兄弟节点、根节点、叶子节点

节点高度（Height）：节点到叶子节点的最长路径（边数）

节点深度（Depth）：节点到根节点的边数

节点层（Level）：节点的深度+1

树的高度（Height）：根节点的高度

##### 二叉树（Binary Tree）

二叉树，顾名思义，每个节点最多有两个“叉”，也就是两个子节点，分别是左子节点和右子节点。

满二叉树：叶子节点全都在最底层，除了叶子节点之外，每个节点都有左右两个子节点。

完全二叉树：叶子节点都在最底下两层，最后一层的叶子节点都靠左排列，并且除了最后一层，其他层的节点个数都要达到最大。

##### 如何表示（存储）一棵二叉树

1. 基于指针或者引用的二叉链式存储法：每个节点有三个字段，其中一个存储数据，另外两个是指向左右子节点的指针。
2. 基于数组的顺序存储法：把根节点存储在下标 i = 1 的位置，那左子节点存储在下标 2 * i = 2 的位置，右子节点存储在 2 * i + 1 = 3 的位置。以此类推，B 节点的左子节点存储在 2 * i = 2 * 2 = 4 的位置，右子节点存储在 2 * i + 1 = 2 * 2 + 1 = 5 的位置。
3. 在基于数组的顺序存储法中，完全二叉树仅仅“浪费”了一个下标为 0 的存储位置。而非完全二叉树，会浪费比较多的数组存储空间。
4. 堆其实就是一种完全二叉树，最常用的存储方式就是数组。

#### 二叉树的遍历

1. 前序遍历：对于树中的任意节点来说，先打印它本身，然后再打印它的左子树，最后打印它的右子树。
2. 中序遍历：对于树中的任意节点来说，先打印它的左子树，然后再打印它本身，最后打印它的右子树。
3. 后序遍历：对于树中的任意节点来说，先打印它的左子树，然后再打印它的右子树，最后打印它本身。
4. 二叉树的前、中、后序遍历就是一个递归的过程。

```
void preOrder(Node* root) {
  if (root == null) return;
  print root // 此处为伪代码，表示打印root节点
  preOrder(root->left);
  preOrder(root->right);
}

void inOrder(Node* root) {
  if (root == null) return;
  inOrder(root->left);
  print root // 此处为伪代码，表示打印root节点
  inOrder(root->right);
}

void postOrder(Node* root) {
  if (root == null) return;
  postOrder(root->left);
  postOrder(root->right);
  print root // 此处为伪代码，表示打印root节点
}
```

5. 按层遍历：使用队列实现。出队的同时，把他的子节点依次入队。

#### 二叉查找树（Binary Search Tree）

二叉查找树是二叉树中最常用的一种类型，也叫二叉搜索树。二叉查找树支持快速查找、快速插入、删除、快速查找最大节点和最小节点、前驱节点和后继节点。

二叉查找树要求，在树中的任意一个节点，其左子树中的每个节点的值，都要小于这个节点的值，而右子树节点的值都大于这个节点的值。

中序遍历二叉查找树，可以输出有序的数据序列，时间复杂度是 O(n)。

##### 二叉树查找树查找

如果要查找的数据比根节点的值小，那就在左子树中递归查找；如果要查找的数据比根节点的值大，那就在右子树中递归查找。

##### 二叉树查找树插入

如果要插入的数据比节点的数据大，并且节点的右子树为空，就将新数据直接插到右子节点的位置；如果不为空，就再递归遍历右子树，查找插入位置。

##### 二叉查找树删除

1. 如果要删除的节点没有子节点，则直接将父节点中，指向要删除节点的指针置为 null。

2. 如果要删除的节点只有一个子节点，我们只需要更新父节点中，指向要删除节点的指针，让它指向要删除节点的子节点。

3. 如果要删除的节点有两个子节点，我们需要找到这个节点的右子树中的最小节点，把它替换到要删除的节点上。然后再删除掉这个最小节点。

##### 支持重复数据的二叉查找树

在实际的软件开发中，可以利用对象的某个字段作为键值（key）来构建二叉查找树。对象中的其他字段叫作卫星数据。这时会存在两个对象键值相等的情况。

方法一：可以通过链表等支持动态扩容的数组等数据结构把键值相同的数据存储在同一个节点上。

方法二：每个节点仍然只存储一个数据。在查找插入位置的过程中，如果碰到一个节点的值，与要插入数据的值相同，我们就将这个要插入的数据放到这个节点的右子树。当要查找数据的时候，遇到值相同的节点，我们并不停止查找操作，而是继续在右子树中查找，直到遇到叶子节点，才停止。这样就可以把键值等于要查找值的所有节点都找出来，删除同理。

#### 平衡二叉查找树

任意一个节点的左右子树的高度相差不能大于 1的二叉树称为平衡二叉树。

最先被发明的平衡二叉查找树是AVL 树，它严格符合平衡二叉查找树的定义。

知名的平衡二叉查找树有伸展树（Splay Tree）、树堆（Treap）、红黑树（Red-Black Tree）等。

红黑树不是一种严格符合要求的平衡二叉树，查找它从根节点到各个叶子节点的最长路径，有可能会比最短路径大一倍。

发明平衡二叉查找树这类数据结构的初衷是，解决普通二叉查找树在频繁的插入、删除等动态更新的情况下，出现时间复杂度退化的问题。

#### 红黑树

##### 基本概念

红黑树是一种近似平衡的二叉查找树，平衡二叉查找树的初衷，是为了解决二叉查找树因为动态更新导致的性能退化问题。所以，“平衡”的意思可以等价为性能不退化。“近似平衡”就等价为性能不会退化得太严重。

红黑树中的节点，一类被标记为黑色，一类被标记为红色。

##### 实现定义

1. 根节点是黑色的（为了简化红黑树的代码实现）。
2. 每个叶子节点都是黑色的空节点（NIL）。
3. 任何相邻的节点都不能同时为红色。
4. 每个节点从该节点到达其可达叶子节点的所有路径，都包含相同数目的黑色节点。

##### 红黑树的实现

1. 左旋（rotate left）、右旋（rotate right）

   针对某节点的旋转，即将该节点的左（右）子节点替换到该节点的位置，左（右）节点的左（右）子节点的位置替换为原节点的右（左）子节点。

2. 插入操作的平衡调整

   红黑树规定，插入的节点必须是红色的。而且，二叉查找树中新插入的节点都是放在叶子节点上。如果插入节点的父节点是红色，则会导致红黑树不符合定义，此时就需要进行旋转和改变颜色，红黑树的平衡调整过程是一个迭代的过程。

   我们把正在处理的节点叫做关注节点，关注节点会随着不停地迭代处理，而不断发生变化。最开始的关注节点就是新插入的节点。

   此时会分为三种情况：

   1）关注节点的叔叔节点为红色，则执行以下操作：将关注节点的父节点、叔叔节点的颜色都设置成黑色；将关注节点的祖父节点的颜色设置成红色；关注节点变成祖父节点；跳到2或者3。

   2）关注节点的叔叔节点是黑色，且关注节点是父节点的右子节点，则执行以下操作：关注节点变成父节点；围绕新的关注节点b 左旋；跳到 CASE  3。

   3）关注节点的叔叔节点是黑色，且关注节点是父节点的左子节点，则执行以下操作：围绕关注节点的祖父节点右旋；将关注节点的父节点、兄弟节点的颜色互换。

3. 删除操作的平衡调整

   删除操作的平衡调整分为两步，第一步是针对删除节点初步调整。初步调整只是保证整棵红黑树在一个节点删除之后，仍然满足最后一条定义的要求；第二步是针对关注节点进行二次调整，让它满足红黑树的第三条定义，即不存在相邻的两个红色节点。

   初步调整

   1）如果要删除的节点只有一个子节点，则执行以下操作：删除该节点，子节点替换原来节点的位置，并将子节点的颜色变成黑色。

   2）如果要删除的节点有两个非空子节点，并且它的后继节点就是节点的右子节点，则执行以下操作：删除该节点，将右子节点替换原来节点的位置，把右子节点设置为原节点相同的颜色。如果右子节点是黑色，则给右子节点的右子节点增加一个黑色。

   3）如果要删除的节点有两个非空子节点，并且它的后继节点不是节点的右子节点，则执行以下操作：找到并删除后继节点，将后继节点替换原节点的位置，把后继节点设置为原节点相同的颜色。如果原节点是黑色，则给原节点的右子节点增加一个黑色。此时，关注节点变成了右子节点，第二步的调整操作就会针对关注节点来做。

   二次调整

   1）如果关注节点的兄弟节点是红色，则执行以下操作：围绕关注节点的父节点左旋，将关注节点的父节点与祖父节点交换颜色。

   2）如果关注节点的兄弟节点是黑色，则执行以下操作：将兄弟节点的颜色变成红色，从关注节点中去掉一个黑色，给关注节点的父节点增加一个黑色，关注节点变成父节点。

   3）如果关注节点的兄弟节点是黑色，且兄弟节点的左子节点是红色，兄弟节点的右子节点是黑色，则执行以下操作：围绕兄弟节点右旋，兄弟节点和兄弟节点的左子节点交换颜色，跳转到4。

   4）如果关注节点的兄弟节点是黑色，且兄弟节点的左子节点是黑色，则执行以下操作：围绕关注节点的父节点左旋，将关注节点的兄弟节点的颜色设置为与关注节点的父节点的颜色相同，将关注节点的父节点设置为黑色，从关注节点中去掉一个黑色，将关注节点的叔叔节点设置为黑色。

### 2.12 递归树（Recursion Tree）

递归的思想就是，将大问题分解为小问题来求解，然后再将小问题分解为小小问题。这样一层一层地分解，直到问题的数据规模被分解得足够小，不用继续递归分解为止。如果我们把这个一层一层的分解过程画成图，其实就是递归树。

#### 递归树与时间复杂度

##### 快排的时间复杂度

已知快排的每一层都需要遍历n个元素，假设每次分区的大小比例为1:k，则递归树的最短路径为log(k+1)n，最长路径为log(k+1/k)n，那么遍历的数据量则位于nlog(k+1)n和nlog(k+1/k)n之间，对底数进行省略，那么平均时间复杂度仍为O（nlogn）。

##### 斐波那契数列的时间复杂度

将n进行分解，每次数据规模都是-1或-2，每次都-1为最长路径n，每次都-2为最短路径n/2，每次合并只需要进行一次加法操作，那么第k层的时间消耗为2^k-1，最好情况的时间消耗为（2^n）-1，最坏情况的时间消耗为（2^n/2）-1，即时间复杂度在O（2^n）和O（2^n/2）之间。

##### 全排列的时间复杂度

从第一位开始计算，第一位可以选择所有的数字，之后每次往后一位则可选择数-1，第一位的时间成本为n，再往后每一位的时间成本都为上一位的可选择数-1再乘以上一位的时间成本，那么公差为1的等差数列积，最后一位的时间成本为n！，前面n-1位的时间成本都小于n！，即时间复杂度在O（n*n！）和O（n！）之间。

### 2.13 堆（Heap）

堆是一种特殊的树，属于非线性表结构，堆排序是一种原地排序算法，时间复杂度为O（nlogn）。

#### 基本概念

1. 堆是一个完全二叉树
2. 堆中的每一个节点的值都大于等于或小于等于其子节点的值。
3. 堆适合用数组进行存储

#### 堆的基本操作

| 排序方法 | 时间复杂度 | 空间复杂度 | 是否基于比较 | 是否稳定 |
| -------- | ---------- | ---------- | ------------ | -------- |
| 堆排序   | O(nlogn)   | O(1)       | 是           | 否       |

##### 堆的插入

往堆中插入一个元素后我们需要对堆重新进行调整来使其满足堆的定义，这个过程称为堆化。堆化分为两种：从上往下和从下往上。

堆化的操作其实就是顺着节点的路径向上或者向下进行对比，交换，直到满足父子节点的大小关系。

##### 堆的删除

如果构造的是大顶堆，当删除堆顶元素之后，就需要把第二大的元素放到堆顶，那第二大元素肯定会出现在左右子节点中。然后再迭代地删除第二大节点，以此类推，直到叶子节点被删除。但这种方法最后堆化出来的堆并不满足完全二叉树的特性。

此时需要用到从上到下的堆化方法：把最后一个节点放到堆顶，然后利用同样的父子节点对比方法。对于不满足父子节点大小关系的，互换两个节点，并且重复进行这个过程，直到父子节点之间满足大小关系为止。

堆的插入和删除操作时间复杂度都取决于堆化时间复杂度，即O(logn)。

#### 基于堆实现排序

##### 步骤一：建堆

首先将数组原地建成一个堆。所谓“原地”就是，不借助另一个数组，就在原数组上操作。建堆的过程，有两种思路。

第一种是借助在堆中插入一个元素的思路。假设堆中只包含一个数据，就是下标为 1 的数据。然后调用插入操作，将下标从 2 到 n 的数据依次插入到堆中。这样就将包含 n 个数据的数组，组织成了堆。

第二种实现思路跟第一种相反。第一种建堆思路的处理过程是从前往后处理数组数据，并且每个数据插入堆中时，都是从下往上堆化。而第二种实现思路，是从后往前处理数组，并且每个数据都是从上往下堆化。

因为叶子节点往下堆化只能自己跟自己比较，所以直接从最后一个非叶子节点（n/2）开始，依次堆化。

根据完全二叉树的性质，（n/2-1）- n都是叶子节点。

每个节点堆化的过程中，需要比较和交换的节点个数，跟这个节点的高度 k 成正比。对每个非叶子节点的高度求和，根据等比数列求和公式，k可以约掉，再代入堆高度logn，可以得到，建堆的时间复杂度是 O(n)。

##### 步骤二：排序

建堆结束之后，数组中的数据已经是按照大顶堆的特性来组织的。数组中的第一个元素就是堆顶，也就是最大的元素。我们把它跟最后一个元素交换，那最大元素就放到了下标为 n 的位置。

堆顶元素移除之后，我们把下标为 n 的元素放到堆顶，然后再通过堆化的方法，将剩下的 n−1 个元素重新构建成堆。

堆化完成之后，我们再取堆顶的元素，放到下标是 n−1 的位置，一直重复这个过程，直到最后堆中只剩下标为 1 的一个元素，排序完成，排序的时间复杂度为O（nlogn）。

##### 快速排序优于堆排序的原因

1. 堆排序数据访问的方式没有快速排序友好。
2. 对于同样的数据，在排序过程中，堆排序算法的数据交换次数要多于快速排序。

#### 堆的应用

##### 堆优先级队列

相关应用：赫夫曼编码、图的最短路径、最小生成树算法

1. 合并有序小文件

   每次在每个小文件中取出一个字符串，构造一个小顶堆，取出堆顶元素，写入到大文件中，再从取出元素的源文件中取出下一个字符串，插入堆，重复以上步骤。

   插入、删除和堆化的时间复杂度都是O（logn）

2. 高性能定时器

   假设存在一个定时器，定时器中维护了很多定时任务，每个任务都设定了一个要触发执行的时间点。按照任务执行的时间顺序构造一个小顶堆，堆顶为最近执行的任务，设置等待时间为堆顶元素执行时间点减去当前时间，定时器到达等待时间后取出堆顶元素进行执行，重复以上步骤。在此方法中省去了定时轮询和遍历的开销。

##### 利用堆求Top K

1. 静态数据集合

   维护一个大小为k的小顶堆，顺序遍历集合，取出元素与堆顶元素进行比较，如果比堆顶元素大，则把堆顶元素删除，将取出元素插入堆中。

2.  动态数据集合

   在静态数据集合的基础上，先对原有元素维护一个大小为k的小顶堆，之后每次有新元素加入集合，则和堆进行比较，操作和原来相同。

##### 利用堆求中位数

1. 静态数据集合

   直接排序，根据元素总个数的奇偶性取n/2或n/2+1，虽然排序的代价很大，但是边际成本很小。

2. 动态数据集合

   需要维护两个堆，一个大顶堆，一个小顶堆。大顶堆维护前半部分数据，小顶堆维护后半部分数据，中位数即大顶堆或小顶堆的堆顶元素。当添加一个新元素时，如果该元素小于等于大顶堆的堆顶元素，则插入大顶堆，否则插入到小顶堆。如果此时两个堆的元素不再符合之前划分的规则，就将多的那个堆的堆顶元素插入到另一个堆中。

   应用此方法，还可以快速求其他百分比的数。

### 2.14 图（Graph）

#### 基本概念

图是一种比树更复杂的非线性表结构，图的元素称为为顶点，顶点之间的连接称为边，每个顶点连接的边数称为度。

边区分方向的图称为有向图，不区分方向的称为无向图，在有向图中，度分为入度（In-degree）和出度（Out-degree），顶点的入度表示有多少个边指向这个顶点，出度表示有多少边以这个顶点为起点。

每条边都有一个权重（weight）的图称为带权图。

#### 邻接矩阵（Adjacency Matrix）存储法

图最直观的一种存储方法就是邻接矩阵。

用邻接矩阵比较浪费存储空间。如果我们存储的是一个无向图，则一条边需要浪费两个单位空间存储一样的数值，如果我们存储的是稀疏图（Sparse Matrix），顶点很多而边很少，则更浪费空间。

邻接矩阵的存储方式简单、直观，且基于数组，在获取两个顶点的关系时非常高效，且矩阵更方便进行运算。

#### 邻接表（Adjacency List）存储方法

邻接表的存储方式类似散列表，每个顶点对应一条链表，链表中存储与该顶点相连接的其他顶点。

邻接表比较节省空间，但是获取两个顶点的关系时效率较低。可以将链表替换为更高效的数据结构如红黑树、跳表、散列表等，或者将链表改成有序动态数组，来提高查找效率。

#### 深度和广度优先搜索（Frist Search）

深度优先搜索算法和广度优先搜索算法都是基于“图”这种数据结构。

图上的搜索算法，最直接的理解就是，在图中找出从一个顶点出发，到另一个顶点的路径。

##### 广度优先搜索（Breadth-First-Search）

广度优先搜索找出来的是两顶点之间的最短路径

时间复杂度为O（E），E为边数，空间复杂度为O（V），V为顶点数。

需要辅助变量：bool数组（存储节点访问记录），队列（存储已被访问，但相连顶点还未被访问的顶点），prev数组（存储访问路径）。

```
public void bfs(int s, int t) {
  if (s == t) return;
  boolean[] visited = new boolean[v];
  visited[s]=true;
  Queue<Integer> queue = new LinkedList<>();
  queue.add(s);
  int[] prev = new int[v];
  for (int i = 0; i < v; ++i) {
    prev[i] = -1;
  }
  while (queue.size() != 0) {
    int w = queue.poll();
   for (int i = 0; i < adj[w].size(); ++i) {
      int q = adj[w].get(i);
      if (!visited[q]) {
        prev[q] = w;
        if (q == t) {
          print(prev, s, t);
          return;
        }
        visited[q] = true;
        queue.add(q);
      }
    }
  }
}

private void print(int[] prev, int s, int t) { // 递归打印s->t的路径
  if (prev[t] != -1 && t != s) {
    print(prev, s, prev[t]);
  }
  System.out.print(t + " ");
}
```

##### 深度优先搜索（Depth-First-Search）

深度优先搜索用的是回溯思想，适合用递归来实现，它找出来的不是两顶点之间的最短路径。

时间复杂度为O(E)，E为边数，空间复杂度为O（V），V为顶点数。

需要辅助变量：bool数组（存储节点访问记录），prev数组（存储访问路径），found（标记查找结果，停止递归）。

```
boolean found = false; // 全局变量或者类成员变量

public void dfs(int s, int t) {
  found = false;
  boolean[] visited = new boolean[v];
  int[] prev = new int[v];
  for (int i = 0; i < v; ++i) {
    prev[i] = -1;
  }
  recurDfs(s, t, visited, prev);
  print(prev, s, t);
}

private void recurDfs(int w, int t, boolean[] visited, int[] prev) {
  if (found == true) return;
  visited[w] = true;
  if (w == t) {
    found = true;
    return;
  }
  for (int i = 0; i < adj[w].size(); ++i) {
    int q = adj[w].get(i);
    if (!visited[q]) {
      prev[q] = w;
      recurDfs(q, t, visited, prev);
    }
  }
}
```

### 2.15 字符串匹配（String match）

#### 基本概念

在字符串A中查找字符串B，则A称为主串，B称为模式串，已知A的程度为n，B的长度为m。

#### 暴力匹配（Brute Force）算法

暴力匹配算法也称为朴素算法（Naive Algorithm），最坏时间复杂度为O（n*m）

暴力匹配就是检查主串中起始位置分别是0，1，2，……，n-m且长度为m的n-m+1个子串是否与模式串匹配。

虽然这种算法复杂度很高，但是实际开发中却比较常用。

1. 实际情况下主串和模式串的长度都不会太大，且大部分不会从头到尾都对比一遍，所以从统计意义上来讲实际效率比理论效率高很多。
2. 暴力匹配思想简单，代码实现也简单，不容易出错。即KISS原则。

#### RK（Rabin-Karp） 算法

RK算法是在暴力匹配的基础上引入了哈希算法，先对模式串求哈希值，再对主串中n-m+1个子串分别求哈希值并与模式串的哈希值进行匹配，时间复杂度为O（n）。

这里会有两个问题，一个是虽然提高了对比效率，但是哈希算法计算哈希值的时候仍然需要遍历整个子串的所有字符，从整体效率来讲并没有提高。第二个是无法避免哈希碰撞问题。

解决以上问题需要设计合理的哈希算法：

1. 假设需要匹配的字符串只包含K个字符，可以用一个K进制数来表示一个子串，将这个K进制数转化成十进制数就是子串的哈希值。
2. 相邻两个子串之间计算哈希值的公式有交集。
3. k的次方值可以先用一个数组来进行存储，通过查表的方式来提高效率，节省计算时间。
4. 特殊情况下如果子串太长生成的哈希值超出了整型范围，则可以考虑重新设计哈希算法，如k个字符分别对应一个值，哈希值为每位字符对应值的和，这种设计可以允许一定程度的哈希冲突，当匹配到哈希值相同的时候，再对原字符串进行比较。

#### BM（Boyer-Moore）算法

BM 算法包含两部分，分别是坏字符规则（bad character rule）和好后缀规则（good suffix shift）。

1. 坏字符规则

   照模式串下标从大到小的顺序，倒着匹配，当发现某个字符没法匹配的时候，我们把这个没有匹配的主串字符叫作坏字符。再拿坏字符串在模式串中进行查找，如果模式串中没有，则讲整个模式串移动到坏字符后面，如果匹配到，则将模式串移动到与坏字符匹配的位置。重复以上步骤。移动距离公式为：发现坏字符的位置-匹配到坏字符的位置。如果坏字符在模式串中多次出现，则选择先匹配到的那个即下标较大的。

   单用坏字符原则可能算出来时负数导致模式串倒退。

2. 好后缀规则

   按照坏字符规则的方式进行匹配，当匹配到坏字符时，前面已经匹配的字符串称为好后缀。在模式串中查找是否存在第二个好后缀，如果存在，则将模式串滑动到匹配的第二个好后缀与主串中好后缀对齐的位置，如果不存在，则在好后缀的后缀子串中找到一个最长且能和模式串的前缀子串匹配的，滑动到主串中该匹配字符串的位置。

3. 分别计算坏字符原则与好后缀原则需要滑动的位数，取最大值。

4. 代码实现：

   坏字符规则的重点在于查找坏字符在模式串中出现的位置，顺序查找效率太低，会影响算法性能。可以使用散列表来存储字符及下标，相同字符取较大下标值。

   ```
   public int bm(char[] a, int n, char[] b, int m) {
     int[] bc = new int[SIZE]; // 记录模式串中每个字符最后出现的位置
     generateBC(b, m, bc); // 构建坏字符哈希表
     int i = 0; // i表示主串与模式串对齐的第一个字符
     while (i <= n - m) {
       int j;
       for (j = m - 1; j >= 0; --j) { // 模式串从后往前匹配
         if (a[i+j] != b[j]) break; // 坏字符对应模式串中的下标是j
       }
       if (j < 0) {
         return i; // 匹配成功，返回主串与模式串第一个匹配的字符的位置
       }
       // 这里等同于将模式串往后滑动j-bc[(int)a[i+j]]位
       i = i + (j - bc[(int)a[i+j]]); 
     }
     return -1;
   }
   ```

   好后缀也是模式串本身的后缀子串，所以可以在开始匹配之前先预处理模式串，计算好模式串中每个后缀子串，对应另一个可匹配子串的位置。后缀子串的最后一位是确定的，所以我们可以通过长度来确定唯一一个子串。

   引入一个整型数组suffix，下标为后缀长度，值为与后缀匹配的子串第一个字符的下标，如果有多个匹配子串，则存取较大值。

   引入一个bool型数组prefix，下标为后缀长度，值为是否能匹配模式串的前缀子串。这里判断值为true的条件是在上一个整形数组中匹配的子串起始位置为0。

   ```
   // b表示模式串，m表示长度，suffix，prefix数组事先申请好了
   private void generateGS(char[] b, int m, int[] suffix, boolean[] prefix) {
     for (int i = 0; i < m; ++i) { // 初始化
       suffix[i] = -1;
       prefix[i] = false;
     }
     for (int i = 0; i < m - 1; ++i) { // b[0, i]
       int j = i;
       int k = 0; // 公共后缀子串长度
       while (j >= 0 && b[j] == b[m-1-k]) { // 与b[0, m-1]求公共后缀子串
         --j;
         ++k;
         suffix[k] = j+1; //j+1表示公共后缀子串在b[0, i]中的起始下标
       }
       if (j == -1) prefix[k] = true; //如果公共后缀子串也是模式串的前缀子串
     }
   }
   ```

   将两种规则综合实现如下

   ```
   // a,b表示主串和模式串；n，m表示主串和模式串的长度。
   public int bm(char[] a, int n, char[] b, int m) {
     int[] bc = new int[SIZE]; // 记录模式串中每个字符最后出现的位置
     generateBC(b, m, bc); // 构建坏字符哈希表
     int[] suffix = new int[m];
     boolean[] prefix = new boolean[m];
     generateGS(b, m, suffix, prefix);
     int i = 0; // j表示主串与模式串匹配的第一个字符
     while (i <= n - m) {
       int j;
       for (j = m - 1; j >= 0; --j) { // 模式串从后往前匹配
         if (a[i+j] != b[j]) break; // 坏字符对应模式串中的下标是j
       }
       if (j < 0) {
         return i; // 匹配成功，返回主串与模式串第一个匹配的字符的位置
       }
       int x = j - bc[(int)a[i+j]];
       int y = 0;
       if (j < m-1) { // 如果有好后缀的话
         y = moveByGS(j, m, suffix, prefix);
       }
       i = i + Math.max(x, y);
     }
     return -1;
   }
   
   // j表示坏字符对应的模式串中的字符下标; m表示模式串长度
   private int moveByGS(int j, int m, int[] suffix, boolean[] prefix) {
     int k = m - 1 - j; // 好后缀长度
     if (suffix[k] != -1) return j - suffix[k] +1;
     for (int r = j+2; r <= m-1; ++r) {
       if (prefix[m-r] == true) {
         return r;
       }
     }
     return m;
   }
   ```

5. 性能分析

   坏字符的查找数组和字符集相关，内存消耗较大，好后缀的整形数组和bool型数组和模式串长度m相关，为O（m），内存消耗较小。所以在内存要求比较严格的情况下可以只使用好后缀规则。

   BM算法的时间复杂度分析比较复杂，根据论文的证明，最坏情况下BM算法的比较次数上限是5n（https://dl.acm.org/doi/10.1109/SFCS.1977.3）或者3n（https://dl.acm.org/doi/10.5555/127787.127830）。

#### KMP（ Knuth Morris Pratt）算法

KMP算法和BM算法类似，但是字符串的比较是从前往后进行，遇到坏字符之前已经匹配好的字符串叫做好前缀，需要找到好前缀中能与前缀子串匹配的最长后缀子串，再将模式串移动到主串中最长可匹配后缀子串和模式串中最长可匹配前缀子串对应的位置。这两个子串分别称为最长可匹配后缀子串/最长可匹配前缀子串。

1. 代码实现

   引入一个整型数组next，下标为模式串前缀的结尾字符下标，值为这个前缀的后缀子串能匹配的最长前缀子串的结尾字符下标。这个数组被称为失效函数（failure function）。

   ```
   // a, b分别是主串和模式串；n, m分别是主串和模式串的长度。
   public static int kmp(char[] a, int n, char[] b, int m) {
     int[] next = getNexts(b, m);
     int j = 0;
     for (int i = 0; i < n; ++i) {
       while (j > 0 && a[i] != b[j]) { // 一直找到a[i]和b[j]
         j = next[j - 1] + 1;
       }
       if (a[i] == b[j]) {
         ++j;
       }
       if (j == m) { // 找到匹配模式串的了
         return i - m + 1;
       }
     }
     return -1;
   }
   ```

   失效函数最简单的计算方法就是把所有后缀子串找出来逐个和前缀子串匹配，但是效率非常低下。由于next的值是逐位计算的，计算next[i]时next[1]-next[i-1]已经计算出来了。

   如果next[i-1]=k-1，则考察[0,i-1]的最长可匹配前缀子串的下一位k与[0,i]的最后一位是否匹配，匹配则可得nxte[i]=k。

   如果上一条不匹配，则考察[0,i-1]的次长可匹配前缀子串[0,i-1-x]的下一个字符i-x与[0,i]的最后一位是否匹配，匹配则[0,i-1-x]对应匹配的次长后缀子串[x,i-1]加上[0,i]的最后一位i即为[0,i]的最长可匹配后缀子串。这里的关键是求次长可匹配后缀子串。

   由于次长可匹配前缀子串一定被包含在最长可匹配前缀子串中，于是这个问题就变成了好前缀的最长可匹配前缀子串的前缀子串和好前缀的后缀子串的最长匹配问题。

   ```
   // b表示模式串，m表示模式串的长度
   private static int[] getNexts(char[] b, int m) {
     int[] next = new int[m];
     next[0] = -1;
     int k = -1;
     for (int i = 1; i < m; ++i) {
       while (k != -1 && b[k + 1] != b[i]) {
         k = next[k];
       }
       if (b[k + 1] == b[i]) {
         ++k;
       }
       next[i] = k;
     }
     return next;
   }
   ```

2. 性能分析

   KPM算法只需要一个额外数组，数组大小和模式串长度m相关，为O（m）。时间复杂度分为两部分：计算next数组和模式串匹配，计算next数组的时间复杂度和模式串长度m相关，模式串匹配的时间复杂度和主串长度n相关，所以总时间复杂度为O（m+n）。

### 2.16 字典树（Trie Tree）

#### 基本概念

字典树是一种专门处理字符串匹配的数据结构，用来解决在一组字符串集合中快速查找某个字符串的问题。

Trie 树的本质，就是利用字符串之间的公共前缀，将重复的前缀合并在一起。其中根节点不包含任何信息。每个节点表示一个字符串中的字符，从根节点到红色节点的一条路径表示一个字符串。

构建字典树的时间复杂度为O（m*len），m为敏感词个数，len为敏感词平均长度。查找时间复杂度为O（k），k为查找字符串的长度。

#### 字典树的基本操作

1. 借助散列表,通过下标与字符映射的数组来存储子节点的指针，逐层映射。

   ```
   public class Trie {
     private TrieNode root = new TrieNode('/'); // 存储无意义字符
   
     // 往Trie树中插入一个字符串
     public void insert(char[] text) {
       TrieNode p = root;
       for (int i = 0; i < text.length; ++i) {
         int index = text[i] - 'a';
         if (p.children[index] == null) {
           TrieNode newNode = new TrieNode(text[i]);
           p.children[index] = newNode;
         }
         p = p.children[index];
       }
       p.isEndingChar = true;
     }
   
     // 在Trie树中查找一个字符串
     public boolean find(char[] pattern) {
       TrieNode p = root;
       for (int i = 0; i < pattern.length; ++i) {
         int index = pattern[i] - 'a';
         if (p.children[index] == null) {
           return false; // 不存在pattern
         }
         p = p.children[index];
       }
       if (p.isEndingChar == false) return false; // 不能完全匹配，只是前缀
       else return true; // 找到pattern
     }
   
     public class TrieNode {
       public char data;
       public TrieNode[] children = new TrieNode[26];
       public boolean isEndingChar = false;
       public TrieNode(char data) {
         this.data = data;
       }
     }
   }
   ```

   借助散列表实现字典树实际上是一种空间换时间的思路。

2. 使用有序数组，数组中的指针按照所指向的字节点中的字符的大小顺序排序，查询时通过二分查找。这样可以节省一定空间，但是插入和查找的速度会受到一定影响。

3. 使用缩点优化等方法节省内存。

#### 字典树和散列表、红黑树的比较

字典树对要处理的字符串有极其严苛的要求。

1. 字符串中包含的字符集不能太大。
2. 要求字符串的前缀重合比较多。
3. 如果要用 Trie 树解决问题，那我们就要自己从零开始实现一个 Trie 树，还要保证没有 bug，这个在工程上是将简单问题复杂化。
4. 通过指针串起来的数据块是不连续的，而 Trie 树中用到了指针，所以，对缓存并不友好。

所以在工程上更倾向于使用散列表和红黑树进行精确查找，而字典树更适合查找前缀匹配的字符串。

### 2.17 AC自动机（Aho-Corasick）

AC自动机是进行敏感词匹配的多模式串匹配算法。

#### 基于单模式串和 Trie 树实现的敏感词过滤

BF、RK、BM、KMP算法都是单模式串匹配算法，Tire树是多模式串匹配算法。

基于单模式串的敏感词匹配每次都需要扫描一遍用户输入的内容，开销较大。

基于Tire树可以对敏感词字典进行预处理，构建完之后每次新增敏感词只需要进行插入操作，查找时对主串和Tire树逐个字符进行匹配，若不匹配则后移一位，这种匹配模式类似BF算法。

#### 经典的多模式串匹配算法：AC 自动机

##### AC自动机的构造

AC 自动机实际上就是在 Trie 树之上，对匹配机制进行改进，增加了类似 KMP 的 next 数组（失败函数）。这里失败函数的构建方法和KMP算法中的方法类似。

```
public void buildFailurePointer() {
  Queue<AcNode> queue = new LinkedList<>();
  root.fail = null;
  queue.add(root);
  while (!queue.isEmpty()) {
    AcNode p = queue.remove();
    for (int i = 0; i < 26; ++i) {
      AcNode pc = p.children[i];
      if (pc == null) continue;
      if (p == root) {
        pc.fail = root;
      } else {
        AcNode q = p.fail;
        while (q != null) {
          AcNode qc = q.children[pc.data - 'a'];
          if (qc != null) {
            pc.fail = qc;
            break;
          }
          q = q.fail;
        }
        if (q == null) {
          pc.fail = root;
        }
      }
      queue.add(pc);
    }
  }
}
```

##### AC自动机匹配

在匹配过程中，主串从 i=0 开始，AC 自动机从指针 p=root 开始，假设模式串是 b，主串是 a。

1. 如果 p 指向的节点有一个等于 b[i]的子节点 x，我们就更新 p 指向 x，这个时候我们需要通过失败指针，检测一系列失败指针为结尾的路径是否是模式串。处理完之后，我们将 i 加一，重复匹配过程；
2. 如果 p 指向的节点没有等于 b[i]的子节点，那失败指针就派上用场了，我们让 p=p->fail，重复匹配过程。

``` 
public void match(char[] text) { // text是主串
  int n = text.length;
  AcNode p = root;
  for (int i = 0; i < n; ++i) {
    int idx = text[i] - 'a';
    while (p.children[idx] == null && p != root) {
      p = p.fail; // 失败指针发挥作用的地方
    }
    p = p.children[idx];
    if (p == null) p = root; // 如果没有匹配的，从root开始重新匹配
    AcNode tmp = p;
    while (tmp != root) { // 打印出可以匹配的模式串
      if (tmp.isEndingChar == true) {
        int pos = i-tmp.length+1;
        System.out.println("匹配起始下标" + pos + "; 长度" + tmp.length);
      }
      tmp = tmp.fail;
    }
  }
}
```

##### 性能分析

根据上节内容，Trie 树构建的时间复杂度是 O（m * len）。

构建失败指针的时间复杂度是O（k * len），m为敏感词个数，k为节点个数，len为敏感词平均长度。

匹配的时间复杂度为O（n*len），n为主串长度。实际情况下接近O（n）。

### 2.18 贪心算法（Greedy Algorithm）

#### 基本概念

针对一组数据，我们定义了限制值和期望值，希望从中选出几个数据，在满足限制值的情况下，期望值最大。

贪心算法的应用有霍夫曼编码（Huffman Coding）、Prim 和 Kruskal 最小生成树算法、 Dijkstra 单源最短路径算法。

#### 贪心算法实现霍夫曼编码

假设有一个包含 1000 个字符的文件，每个字符占 1 个 byte（1byte=8bits），存储这 1000 个字符就一共需要 8000bits，如何进行存储空间优化？

##### 基础方法

通过统计分析发现，这 1000 个字符中只包含 6 种不同字符，假设它们分别是 a、b、c、d、e、f。而 3 个二进制位（bit）就可以表示 8 个不同的字符，所以，为了尽量减少存储空间，每个字符用 3 个二进制位来表示。那存储这 1000 个字符只需要 3000bits。

##### 霍夫曼编码方法

1. 考察文本中有多少个不同字符和每个字符出现的频率，根据频率的不同，选择不同长度的编码。根据贪心的思想，可以把出现频率比较多的字符，用稍微短一些的编码；出现频率比较少的字符，用稍微长一些的编码。

   为了避免解压缩过程中的歧义，霍夫曼编码要求各个字符的编码之间，不会出现某个编码是另一个编码前缀的情况。

2. 把每个字符看作一个节点，并且附带着把频率放到优先级队列中。我们从队列中取出频率最小的两个节点 A、B，然后新建一个节点 C，把频率设置为两个节点的频率之和，并把这个新节点 C 作为节点 A、B 的父节点。最后再把 C 节点放入到优先级队列中。重复这个过程，直到队列中没有数据。

   构建完之后给每一条边加上画一个权值，指向左子节点的边标记为 0，指向右子节点的边标记为 1，那从根节点到叶节点的路径就是叶节点对应字符的霍夫曼编码。

### 2.19 分治算法（Divide and Conquer）

#### 基本概念

分治算法（divide and conquer）的核心思想其实就是四个字，分而治之 ，也就是将原问题划分成 n 个规模较小，并且结构与原问题相似的子问题，递归地解决这些子问题，然后再合并其结果，就得到原问题的解。

分治算法是一种处理问题的思想，递归是一种编程技巧。分治算法一般都比较适合用递归来实现。

分治算法的递归实现中都会涉及三个操作

1. 分解：将原问题分解成一系列子问题。
2. 解决：递归地求解各个子问题，若子问题足够小，则直接求解。
3. 合并：将子问题的结果合并成原问题。

分治算法能解决的问题，一般需要满足下面这几个条件。

1. 原问题与分解成的小问题具有相同的模式。
2. 原问题分解成的子问题可以独立求解，子问题之间没有相关性，这一点是分治算法跟动态规划的明显区别。
3. 具有分解终止条件，也就是说，当问题足够小时，可以直接求解。
4. 可以将子问题合并成原问题，而这个合并操作的复杂度不能太高，否则就起不到减小算法总体复杂度的效果。

### 分治思想应用

#### 归并算法求数组逆序度

```
private int num = 0; // 全局变量或者成员变量

public int count(int[] a, int n) {
  num = 0;
  mergeSortCounting(a, 0, n-1);
  return num;
}

private void mergeSortCounting(int[] a, int p, int r) {
  if (p >= r) return;
  int q = (p+r)/2;
  mergeSortCounting(a, p, q);
  mergeSortCounting(a, q+1, r);
  merge(a, p, q, r);
}

private void merge(int[] a, int p, int q, int r) {
  int i = p, j = q+1, k = 0;
  int[] tmp = new int[r-p+1];
  while (i<=q && j<=r) {
    if (a[i] <= a[j]) {
      tmp[k++] = a[i++];
    } else {
      num += (q-i+1); // 统计p-q之间，比a[j]大的元素个数
      tmp[k++] = a[j++];
    }
  }
  while (i <= q) { // 处理剩下的
    tmp[k++] = a[i++];
  }
  while (j <= r) { // 处理剩下的
    tmp[k++] = a[j++];
  }
  for (i = 0; i <= r-p; ++i) { // 从tmp拷贝回a
    a[p+i] = tmp[i];
  }
}
```

#### 分治思想在海量数据处理中的应用

将大文件拆分成小文件，再由不同的执行机执行，执行完之后再进行整合。

### 2.20 回溯算法（Backtracking Algorithm）

很多经典的数学问题都可以用回溯算法解决，比如数独、八皇后、0-1 背包、图的着色、旅行商问题、数独、全排列等等，深度优先算法利用的也是回溯思想。回溯算法非常适合用递归代码实现。

#### 基本概念

回溯的处理思想，有点类似枚举搜索。我们枚举所有的解，找到满足期望的解。为了有规律地枚举所有可能的解，避免遗漏和重复，我们把问题求解的过程分为多个阶段。每个阶段，我们都会面对一个岔路口，我们先随意选一条路走，当发现这条路走不通的时候（不符合期望的解），就回退到上一个岔路口，另选一种走法继续走。

#### 回溯思想应用

##### 八皇后问题

```
int[] result = new int[8];//全局或成员变量,下标表示行,值表示queen存储在哪一列
public void cal8queens(int row) { // 调用方式：cal8queens(0);
  if (row == 8) { // 8个棋子都放置好了，打印结果
    printQueens(result);
    return; // 8行棋子都放好了，已经没法再往下递归了，所以就return
  }
  for (int column = 0; column < 8; ++column) { // 每一行都有8中放法
    if (isOk(row, column)) { // 有些放法不满足要求
      result[row] = column; // 第row行的棋子放到了column列
      cal8queens(row+1); // 考察下一行
    }
  }
}

private boolean isOk(int row, int column) {//判断row行column列放置是否合适
  int leftup = column - 1, rightup = column + 1;
  for (int i = row-1; i >= 0; --i) { // 逐行往上考察每一行
    if (result[i] == column) return false; // 第i行的column列有棋子吗？
    if (leftup >= 0) { // 考察左上对角线：第i行leftup列有棋子吗？
      if (result[i] == leftup) return false;
    }
    if (rightup < 8) { // 考察右上对角线：第i行rightup列有棋子吗？
      if (result[i] == rightup) return false;
    }
    --leftup; ++rightup;
  }
  return true;
}

private void printQueens(int[] result) { // 打印出一个二维矩阵
  for (int row = 0; row < 8; ++row) {
    for (int column = 0; column < 8; ++column) {
      if (result[row] == column) System.out.print("Q ");
      else System.out.print("* ");
    }
    System.out.println();
  }
  System.out.println();
}
```

##### 0-1背包问题

```
public int maxW = Integer.MIN_VALUE; //存储背包中物品总重量的最大值
// cw表示当前已经装进去的物品的重量和；i表示考察到哪个物品了；
// w背包重量；items表示每个物品的重量；n表示物品个数
// 假设背包可承受重量100，物品个数10，物品重量存储在数组a中，那可以这样调用函数：
// f(0, 0, a, 10, 100)
public void f(int i, int cw, int[] items, int n, int w) {
  if (cw == w || i == n) { // cw==w表示装满了;i==n表示已经考察完所有的物品
    if (cw > maxW) maxW = cw;
    return;
  }
  f(i+1, cw, items, n, w);//重点，选择装或者不装
  if (cw + items[i] <= w) {// 已经超过可以背包承受的重量的时候，就不要再装了
    f(i+1,cw + items[i], items, n, w);
  }
}
```

##### 正则表达式

```
public class Pattern {
  private boolean matched = false;
  private char[] pattern; // 正则表达式
  private int plen; // 正则表达式长度

  public Pattern(char[] pattern, int plen) {
    this.pattern = pattern;
    this.plen = plen;
  }

  public boolean match(char[] text, int tlen) { // 文本串及长度
    matched = false;
    rmatch(0, 0, text, tlen);
    return matched;
  }

  private void rmatch(int ti, int pj, char[] text, int tlen) {
    if (matched) return; // 如果已经匹配了，就不要继续递归了
    if (pj == plen) { // 正则表达式到结尾了
      if (ti == tlen) matched = true; // 文本串也到结尾了
      return;
    }
    if (pattern[pj] == '*') { // *匹配任意个字符
      for (int k = 0; k <= tlen-ti; ++k) {
        rmatch(ti+k, pj+1, text, tlen);
      }
    } else if (pattern[pj] == '?') { // ?匹配0个或者1个字符
      rmatch(ti, pj+1, text, tlen);
      rmatch(ti+1, pj+1, text, tlen);
    } else if (ti < tlen && pattern[pj] == text[ti]) { // 纯字符匹配才行
      rmatch(ti+1, pj+1, text, tlen);
    }
}
```

### 2.21 动态规划（Dynamic Programming）

#### 初识动态规划

##### 动态规划实现0-1背包问题

回溯算法实现

```
// 回溯算法实现。注意：我把输入的变量都定义成了成员变量。
private int maxW = Integer.MIN_VALUE; // 结果放到maxW中
private int[] weight = {2，2，4，6，3};  // 物品重量
private int n = 5; // 物品个数
private int w = 9; // 背包承受的最大重量
public void f(int i, int cw) { // 调用f(0, 0)
  if (cw == w || i == n) { // cw==w表示装满了，i==n表示物品都考察完了
    if (cw > maxW) maxW = cw;
    return;
  }
  f(i+1, cw); // 选择不装第i个物品
  if (cw + weight[i] <= w) {
    f(i+1,cw + weight[i]); // 选择装第i个物品
  }
}
```

动态规划实现

```
weight:物品重量，n:物品个数，w:背包可承载重量
public int knapsack(int[] weight, int n, int w) {
  boolean[][] states = new boolean[n][w+1]; // 默认值false
  states[0][0] = true;  // 第一行的数据要特殊处理，可以利用哨兵优化
  if (weight[0] <= w) {
    states[0][weight[0]] = true;
  }
  for (int i = 1; i < n; ++i) { // 动态规划状态转移
    for (int j = 0; j <= w; ++j) {// 不把第i个物品放入背包
      if (states[i-1][j] == true) states[i][j] = states[i-1][j];
    }
    for (int j = 0; j <= w-weight[i]; ++j) {//把第i个物品放入背包
      if (states[i-1][j]==true) states[i][j+weight[i]] = true;
    }
  }
  for (int i = w; i >= 0; --i) { // 输出结果
    if (states[n-1][i] == true) return i;
  }
  return 0;
}
```

对上述代码的空间消耗进行优化

```
public static int knapsack2(int[] items, int n, int w) {
  boolean[] states = new boolean[w+1]; // 默认值false
  states[0] = true;  // 第一行的数据要特殊处理，可以利用哨兵优化
  if (items[0] <= w) {
    states[items[0]] = true;
  }
  for (int i = 1; i < n; ++i) { // 动态规划
    for (int j = w-items[i]; j >= 0; --j) {//把第i个物品放入背包,重点
      if (states[j]==true) states[j+items[i]] = true;
    }
  }
  for (int i = w; i >= 0; --i) { // 输出结果
    if (states[i] == true) return i;
  }
  return 0;
}
```

提示：item中存储的是items中各个变量的随机组合相加的值，值存在且小于w则为true，大于w抛弃不存。

##### 0-1背包问题升级版

回溯算法实现

```
private int maxV = Integer.MIN_VALUE; // 结果放到maxV中
private int[] items = {2，2，4，6，3};  // 物品的重量
private int[] value = {3，4，8，9，6}; // 物品的价值
private int n = 5; // 物品个数
private int w = 9; // 背包承受的最大重量
public void f(int i, int cw, int cv) { // 调用f(0, 0, 0)
  if (cw == w || i == n) { // cw==w表示装满了，i==n表示物品都考察完了
    if (cv > maxV) maxV = cv;
    return;
  }
  f(i+1, cw, cv); // 选择不装第i个物品
  if (cw + weight[i] <= w) {
    f(i+1,cw+weight[i], cv+value[i]); // 选择装第i个物品
  }
}
```

动态规划实现

```
public static int knapsack3(int[] weight, int[] value, int n, int w) {
  int[][] states = new int[n][w+1];
  for (int i = 0; i < n; ++i) { // 初始化states
    for (int j = 0; j < w+1; ++j) {
      states[i][j] = -1;
    }
  }
  states[0][0] = 0;
  if (weight[0] <= w) {
    states[0][weight[0]] = value[0];
  }
  for (int i = 1; i < n; ++i) { //动态规划，状态转移
    for (int j = 0; j <= w; ++j) { // 不选择第i个物品
      if (states[i-1][j] >= 0) states[i][j] = states[i-1][j];
    }
    for (int j = 0; j <= w-weight[i]; ++j) { // 选择第i个物品
      if (states[i-1][j] >= 0) {
        int v = states[i-1][j] + value[i];
        if (v > states[i][j+weight[i]]) {
          states[i][j+weight[i]] = v;
        }
      }
    }
  }
  // 找出最大值
  int maxvalue = -1;
  for (int j = 0; j <= w; ++j) {
    if (states[n-1][j] > maxvalue) maxvalue = states[n-1][j];
  }
  return maxvalue;
}
```

#### “一个模型三个特征”理论

##### 一个模型

###### 多阶段决策最优解模型

解决问题的过程，需要经历多个决策阶段。每个决策阶段都对应着一组状态。然后我们寻找一组决策序列，经过这组决策序列，能够产生最终期望求解的最优值。

##### 三个特征

###### 最优子结构

问题的最优解包含子问题的最优解。反过来说就是，可以通过子问题的最优解，推导出问题的最优解。也就是说，后面阶段的状态可以通过前面阶段的状态推导出来。

###### 无后效性

1. 在推导后面阶段的状态的时候，我们只关心前面阶段的状态值，不关心这个状态是怎么一步一步推导出来的。
2. 某阶段状态一旦确定，就不受之后阶段的决策影响。

###### 重复子问题

不同的决策序列，到达某个相同的阶段时，可能会产生重复的状态。

#### 两种动态规划解题思路

##### 状态转移表法

一般能用动态规划解决的问题，都可以使用回溯算法的暴力搜索解决。

根据回溯算法画出递归树，从递归树中可以看出来，是否存在重复子问题，以及重复子问题是如何产生的。以此来寻找规律，看是否能用动态规划解决。

找到重复子问题之后，有两种处理思路

1. 直接用回溯加“备忘录”，来避免重复子问题。从执行效率上来讲，跟动态规划的解决思路没有差别。
2. 第二种是使用动态规划的解决方法，状态转移表法。状态表一般都是二维的，每个状态包含三个变量，行、列、数组值。根据决策的先后过程，从前往后，根据递推关系，分阶段填充状态表中的每个状态。

##### 状态转移方程法

状态转移方程法有点类似递归的解题思路。首先需要分析，某个问题如何通过子问题来递归求解，也就是最优子结构。根据最优子结构，写出递归公式，即状态转移方程。

一般情况下，我们有两种代码实现方法，一种是递归加“备忘录”，另一种是迭代递推。

##### 动态规划解决最短路径问题

回溯算法实现

```
private int minDist = Integer.MAX_VALUE; // 全局变量或者成员变量
// 调用方式：minDistBacktracing(0, 0, 0, w, n);
public void minDistBT(int i, int j, int dist, int[][] w, int n) {
  if (i == n && j == n) {
    if (dist < minDist) minDist = dist;
    return;
  }
  if (i < n) { // 往下走，更新i=i+1, j=j
    minDistBT(i + 1, j, dist+w[i][j], w, n);
  }
  if (j < n) { // 往右走，更新i=i, j=j+1
    minDistBT(i, j+1, dist+w[i][j], w, n);
  }
}
```

状态转移表法实现

```
public int minDistDP(int[][] matrix, int n) {
  int[][] states = new int[n][n];
  int sum = 0;
  for (int j = 0; j < n; ++j) { // 初始化states的第一行数据
    sum += matrix[0][j];
    states[0][j] = sum;
  }
  sum = 0;
  for (int i = 0; i < n; ++i) { // 初始化states的第一列数据
    sum += matrix[i][0];
    states[i][0] = sum;
  }
  for (int i = 1; i < n; ++i) {
    for (int j = 1; j < n; ++j) {
      states[i][j] = 
            matrix[i][j] + Math.min(states[i][j-1], states[i-1][j]);
    }
  }
  return states[n-1][n-1];
}
```

状态转移方程法实现

```
private int[][] mem = new int[n][n];
public int minDist(int i, int j) { // 调用minDist(n-1, n-1);
  if (i == 0 && j == 0) return matrix[0][0];
  if (mem[i][j] > 0) return mem[i][j];
  int minLeft = Integer.MAX_VALUE;
  if (j-1 >= 0) {
    minLeft = minDist(i, j-1);
  }
  int minUp = Integer.MAX_VALUE;
  if (i-1 >= 0) {
    minUp = minDist(i-1, j);
  }
  
  int currMinDist = matrix[i][j] + Math.min(minLeft, minUp);
  mem[i][j] = currMinDist;
  return currMinDist;
}
```

##### 动态规划实现拼写纠错

###### 量化两个字符串的相似度

有一个非常著名的量化方法，叫编辑距离（Edit Distance）。

编辑距离指的就是，将一个字符串转化成另一个字符串，需要的最少编辑操作次数（比如增加一个字符、删除一个字符、替换一个字符）。编辑距离越大，说明两个字符串的相似程度越小；相反，编辑距离就越小，说明两个字符串的相似程度越大。

编辑距离有多种不同的计算方式，比较著名的有莱文斯坦距离（Levenshtein distance）和最长公共子串长度（Longest common substring length）。莱文斯坦距离允许增加、删除、替换字符这三个编辑操作，最长公共子串长度只允许增加、删除字符这两个编辑操作。

###### 莱文斯坦距离实现

这个问题是求把一个字符串变成另一个字符串，需要的最少编辑次数。整个求解过程，涉及多个决策阶段，需要依次考察一个字符串中的每个字符，跟另一个字符串中的字符是否匹配，匹配的话如何处理，不匹配的话又如何处理。所以这个问题符合多阶段决策最优解模型。

回溯思想实现

如果 a[i]与 b[j]匹配，我们递归考察 a[i+1]和 b[j+1]。

如果 a[i]与 b[j]不匹配，那我们有多种处理方式可选：

1. 删除 a[i]，然后递归考察 a[i+1]和 b[j]；
2. 删除 b[j]，然后递归考察 a[i]和 b[j+1]；
3. 在 a[i]前面添加一个跟 b[j]相同的字符，然后递归考察 a[i]和 b[j+1]；
4. 在 b[j]前面添加一个跟 a[i]相同的字符，然后递归考察 a[i+1]和 b[j]；
5. 将 a[i]替换成 b[j]，或者将 b[j]替换成 a[i]，然后递归考察 a[i+1]和 b[j+1]。

```
private char[] a = "mitcmu".toCharArray();
private char[] b = "mtacnu".toCharArray();
private int n = 6;
private int m = 6;
private int minDist = Integer.MAX_VALUE; // 存储结果
// 调用方式 lwstBT(0, 0, 0);
public lwstBT(int i, int j, int edist) {
  if (i == n || j == m) {
    if (i < n) edist += (n-i);
    if (j < m) edist += (m - j);
    if (edist < minDist) minDist = edist;
    return;
  }
  if (a[i] == b[j]) { // 两个字符匹配
    lwstBT(i+1, j+1, edist);
  } else { // 两个字符不匹配
    lwstBT(i + 1, j, edist + 1); // 删除a[i]或者b[j]前添加一个字符
    lwstBT(i, j + 1, edist + 1); // 删除b[j]或者a[i]前添加一个字符
    lwstBT(i + 1, j + 1, edist + 1); // 将a[i]和b[j]替换为相同字符
  }
}
```

动态规划实现

状态转移方程

如果：a[i]!=b[j]，那么：min_edist(i, j)就等于：
min(min_edist(i-1,j)+1, min_edist(i,j-1)+1, min_edist(i-1,j-1)+1)

如果：a[i]==b[j]，那么：min_edist(i, j)就等于：
min(min_edist(i-1,j)+1, min_edist(i,j-1)+1，min_edist(i-1,j-1)) 

```
public int lwstDP(char[] a, int n, char[] b, int m) {
  int[][] minDist = new int[n][m];
  for (int j = 0; j < m; ++j) { // 初始化第0行:a[0..0]与b[0..j]的编辑距离
    if (a[0] == b[j]) minDist[0][j] = j;
    else if (j != 0) minDist[0][j] = minDist[0][j-1]+1;
    else minDist[0][j] = 1;
  }
  for (int i = 0; i < n; ++i) { // 初始化第0列:a[0..i]与b[0..0]的编辑距离
    if (a[i] == b[0]) minDist[i][0] = i;
    else if (i != 0) minDist[i][0] = minDist[i-1][0]+1;
    else minDist[i][0] = 1;
  }
  for (int i = 1; i < n; ++i) { // 按行填表
    for (int j = 1; j < m; ++j) {
      if (a[i] == b[j]) minDist[i][j] = min(
          minDist[i-1][j]+1, minDist[i][j-1]+1, minDist[i-1][j-1]);
      else minDist[i][j] = min(
          minDist[i-1][j]+1, minDist[i][j-1]+1, minDist[i-1][j-1]+1);
    }
  }
  return minDist[n-1][m-1];
}

private int min(int x, int y, int z) {
  int minv = Integer.MAX_VALUE;
  if (x < minv) minv = x;
  if (y < minv) minv = y;
  if (z < minv) minv = z;
  return minv;
}
```

###### 最长公共子串长度实现

回溯思想实现

如果 a[i]与 b[j]互相匹配，我们将最大公共子串长度加一，并且继续考察 a[i+1]和 b[j+1]。

如果 a[i]与 b[j]不匹配，最长公共子串长度不变，这个时候，有两个不同的决策路线：

1. 删除 a[i]，或者在 b[j]前面加上一个字符 a[i]，然后继续考察 a[i+1]和 b[j]；
2. 删除 b[j]，或者在 a[i]前面加上一个字符 b[j]，然后继续考察 a[i]和 b[j+1]。

动态规划实现

状态转移方程

如果：a[i]==b[j]，那么：max_lcs(i, j)就等于：
max(max_lcs(i-1,j-1)+1, max_lcs(i-1, j), max_lcs(i, j-1))

如果：a[i]!=b[j]，那么：max_lcs(i, j)就等于：
max(max_lcs(i-1,j-1), max_lcs(i-1, j), max_lcs(i, j-1))

```
public int lcs(char[] a, int n, char[] b, int m) {
  int[][] maxlcs = new int[n][m];
  for (int j = 0; j < m; ++j) {//初始化第0行：a[0..0]与b[0..j]的maxlcs
    if (a[0] == b[j]) maxlcs[0][j] = 1;
    else if (j != 0) maxlcs[0][j] = maxlcs[0][j-1];
    else maxlcs[0][j] = 0;
  }
  for (int i = 0; i < n; ++i) {//初始化第0列：a[0..i]与b[0..0]的maxlcs
    if (a[i] == b[0]) maxlcs[i][0] = 1;
    else if (i != 0) maxlcs[i][0] = maxlcs[i-1][0];
    else maxlcs[i][0] = 0;
  }
  for (int i = 1; i < n; ++i) { // 填表
    for (int j = 1; j < m; ++j) {
      if (a[i] == b[j]) maxlcs[i][j] = max(
          maxlcs[i-1][j], maxlcs[i][j-1], maxlcs[i-1][j-1]+1);
      else maxlcs[i][j] = max(
          maxlcs[i-1][j], maxlcs[i][j-1], maxlcs[i-1][j-1]);
    }
  }
  return maxlcs[n-1][m-1];
}

private int max(int x, int y, int z) {
  int maxv = Integer.MIN_VALUE;
  if (x > maxv) maxv = x;
  if (y > maxv) maxv = y;
  if (z > maxv) maxv = z;
  return maxv;
}
```

### 2.22 四种算法思想比较分析

对四种算法思想进行分类，贪心、回溯、动态规划可以归为一类，分治单独作为一类。前三个算法解决问题的模型，都可以抽象成多阶段决策最优解模型，而分治算法解决的问题尽管大部分也是最优解问题，但大部分都不能抽象成多阶段决策模型。

回溯算法相当于穷举搜索。穷举所有的情况，然后对比得到最优解。但回溯算法的时间复杂度非常高，是指数级别的，只能用来解决小规模数据的问题。

动态规划解决的问题，需要满足三个特征，最优子结构、无后效性和重复子问题。动态规划和分治算法的区分非常明显。分治算法要求分割成的子问题，不能有重复子问题，而动态规划正好相反。动态规划之所以高效，就是因为回溯算法实现中存在大量的重复子问题。

贪心算法实际上是动态规划算法的一种特殊情况。它解决问题起来更加高效，代码实现也更加简洁。不过可以解决的问题也更加有限。它能解决的问题需要满足三个条件，最优子结构、无后效性和贪心选择性。

## 三、高级篇
### 3.1 拓扑排序（Topological Sorting）

#### 基本概念

拓扑排序是基于有向无环图的一个算法，可以用来解决依赖顺序问题。

#### 数据结构实现

```
public class Graph {
  private int v; // 顶点的个数
  private LinkedList<Integer> adj[]; // 邻接表

  public Graph(int v) {
    this.v = v;
    adj = new LinkedList[v];
    for (int i=0; i<v; ++i) {
      adj[i] = new LinkedList<>();
    }
  }

  public void addEdge(int s, int t) { // s先于t，边s->t
    adj[s].add(t);
  }
}
```

#### 算法实现

##### Kahn算法实现

Kahn算法运用的是贪心算法思想。

定义数据结构的时候，如果 s 需要先于 t 执行，那就添加一条 s 指向 t 的边。所以，如果某个顶点入度为 0， 也就表示，没有任何顶点必须先于这个顶点执行，那么这个顶点就可以执行了。

找出一个入度为 0 的顶点，添加到结果序列中，再将这个顶点从图中删除，循环该过程，直到所有的顶点都被输出。

```
public void topoSortByKahn() {
  int[] inDegree = new int[v]; // 统计每个顶点的入度
  for (int i = 0; i < v; ++i) {
    for (int j = 0; j < adj[i].size(); ++j) {
      int w = adj[i].get(j); // i->w
      inDegree[w]++;
    }
  }
  LinkedList<Integer> queue = new LinkedList<>();
  for (int i = 0; i < v; ++i) {
    if (inDegree[i] == 0) queue.add(i);
  }
  while (!queue.isEmpty()) {
    int i = queue.remove();
    System.out.print("->" + i);
    for (int j = 0; j < adj[i].size(); ++j) {
      int k = adj[i].get(j);
      inDegree[k]--;
      if (inDegree[k] == 0) queue.add(k);
    }
  }
}
```

##### DFS算法实现

这个算法包含两个关键部分:

1. 通过邻接表构造逆邻接表。
2. 递归处理每个顶点。

```
public void topoSortByDFS() {
  // 先构建逆邻接表，边s->t表示，s依赖于t，t先于s
  LinkedList<Integer> inverseAdj[] = new LinkedList[v];
  for (int i = 0; i < v; ++i) { // 申请空间
    inverseAdj[i] = new LinkedList<>();
  }
  for (int i = 0; i < v; ++i) { // 通过邻接表生成逆邻接表
    for (int j = 0; j < adj[i].size(); ++j) {
      int w = adj[i].get(j); // i->w
      inverseAdj[w].add(i); // w->i
    }
  }
  boolean[] visited = new boolean[v];
  for (int i = 0; i < v; ++i) { // 深度优先遍历图
    if (visited[i] == false) {
      visited[i] = true;
      dfs(i, inverseAdj, visited);
    }
  }
}

private void dfs(
    int vertex, LinkedList<Integer> inverseAdj[], boolean[] visited) {
  for (int i = 0; i < inverseAdj[vertex].size(); ++i) {
    int w = inverseAdj[vertex].get(i);
    if (visited[w] == true) continue;
    visited[w] = true;
    dfs(w, inverseAdj, visited);
  } // 先把vertex这个顶点可达的所有顶点都打印出来之后，再打印它自己
  System.out.print("->" + vertex);
}
```

##### 性能分析

Kahn算法和DFS算法的时间复杂度都是O（V+E），E为边数，V为顶点数。

### 3.2 最短路径算法（Shortest Path Algorithm）

最短路径算法即在一个有向有权图中，求两个顶点间的最短路径。

#### 数据结构实现

```
public class Graph { // 有向有权图的邻接表表示
  private LinkedList<Edge> adj[]; // 邻接表
  private int v; // 顶点个数

  public Graph(int v) {
    this.v = v;
    this.adj = new LinkedList[v];
    for (int i = 0; i < v; ++i) {
      this.adj[i] = new LinkedList<>();
    }
  }

  public void addEdge(int s, int t, int w) { // 添加一条边
    this.adj[s].add(new Edge(s, t, w));
  }

  private class Edge {
    public int sid; // 边的起始顶点编号
    public int tid; // 边的终止顶点编号
    public int w; // 权重
    public Edge(int sid, int tid, int w) {
      this.sid = sid;
      this.tid = tid;
      this.w = w;
    }
  }
  // 下面这个类是为了dijkstra实现用的
  private class Vertex {
    public int id; // 顶点编号ID
    public int dist; // 从起始顶点到这个顶点的距离
    public Vertex(int id, int dist) {
      this.id = id;
      this.dist = dist;
    }
  }
}
```

#### 算法实现

##### 单源最短路径算法（Dijkstra）实现

使用vertexes数组，记录从起始顶点到每个顶点的距离（dist），dist初始化为无限大。

把起始顶点的 dist 值初始化为 0，然后将其放到优先级队列中。

从优先级队列中取出 dist 最小的顶点 minVertex，然后考察这个顶点可达的所有顶点（ nextVertex）。

如果 minVertex 的 dist 值加上 minVertex 与 nextVertex 之间边的权重 w 小于 nextVertex 当前的 dist 值，则把 nextVertex 的 dist 更新为 minVertex 的 dist 值加上 w，再把 nextVertex 加入到优先级队列中。

重复这个过程，直到找到终止顶点 t 或者队列为空。

```
// 因为Java提供的优先级队列，没有暴露更新数据的接口，所以我们需要重新实现一个
private class PriorityQueue { // 根据vertex.dist构建小顶堆
  private Vertex[] nodes;
  private int count;
  public PriorityQueue(int v) {
    this.nodes = new Vertex[v+1];
    this.count = v;
  }
  public Vertex poll() { // TODO: 留给读者实现... }
  public void add(Vertex vertex) { // TODO: 留给读者实现...}
  // 更新结点的值，并且从下往上堆化，重新符合堆的定义。时间复杂度O(logn)。
  public void update(Vertex vertex) { // TODO: 留给读者实现...} 
  public boolean isEmpty() { // TODO: 留给读者实现...}
}

public void dijkstra(int s, int t) { // 从顶点s到顶点t的最短路径
  int[] predecessor = new int[this.v]; // 用来还原最短路径
  Vertex[] vertexes = new Vertex[this.v];
  for (int i = 0; i < this.v; ++i) {
    vertexes[i] = new Vertex(i, Integer.MAX_VALUE);
  }
  PriorityQueue queue = new PriorityQueue(this.v);// 小顶堆
  boolean[] inqueue = new boolean[this.v]; // 标记是否进入过队列
  vertexes[s].dist = 0;
  queue.add(vertexes[s]);
  inqueue[s] = true;
  while (!queue.isEmpty()) {
    Vertex minVertex= queue.poll(); // 取堆顶元素并删除
    if (minVertex.id == t) break; // 最短路径产生了
    for (int i = 0; i < adj[minVertex.id].size(); ++i) {
      Edge e = adj[minVertex.id].get(i); // 取出一条minVetex相连的边
      Vertex nextVertex = vertexes[e.tid]; // minVertex-->nextVertex
      if (minVertex.dist + e.w < nextVertex.dist) { // 更新next的dist
        nextVertex.dist = minVertex.dist + e.w;
        predecessor[nextVertex.id] = minVertex.id;
        if (inqueue[nextVertex.id] == true) {
          queue.update(nextVertex); // 更新队列中的dist值
        } else {
          queue.add(nextVertex);
          inqueue[nextVertex.id] = true;
        }
      }
    }
  }
  // 输出最短路径
  System.out.print(s);
  print(s, t, predecessor);
}

private void print(int s, int t, int[] predecessor) {
  if (s == t) return;
  print(s, predecessor[t], predecessor);
  System.out.print("->" + t);
}
```

##### 性能分析

while和for循环嵌套中，while循环最多执行V次，for循环执行的次数最大不会超过边数E，而for循环内部涉及到堆操作，时间复杂度为为O（logV），综合两部分，时间复杂度为O（E*logV）。

### 3.3 位图（Bit Map）

#### 基本概念

位图是一种比较特殊的散列。

#### 位图实现查找去重

数据范围为1亿，数据量为1千万，如何查找某个数字是否存在于这1千万个数据中。

##### 位图实现

假设申请一个大小为 1 亿、数据类型为bool类型的数组。再将 1 千万个整数作为数组下标，将对应的数组值设置成 true。

查询某个整数 K 是否在这 1 千万个整数中的时候，我们只需要将对应的数组值 array[K]取出来，看是否等于 true。

由于很多语言中的bool类型大小为1个字节，实际上我们只需要1个bit就可以。这里可以通过位运算来进行优化。

```
public class BitMap { // Java中char类型占16bit，也即是2个字节
  private char[] bytes;
  private int nbits;
  
  public BitMap(int nbits) {
    this.nbits = nbits;
    this.bytes = new char[nbits/16+1];
  }

  public void set(int k) {
    if (k > nbits) return;
    int byteIndex = k / 16;
    int bitIndex = k % 16;
    bytes[byteIndex] |= (1 << bitIndex);
  }

  public boolean get(int k) {
    if (k > nbits) return false;
    int byteIndex = k / 16;
    int bitIndex = k % 16;
    return (bytes[byteIndex] & (1 << bitIndex)) != 0;
  }
}
```

##### 布隆过滤器（Bloom Filter）

在之前的问题中，数据范围为一亿时，使用位图的空间消耗比散列表更优，但当数据范围大幅上升，位图的空间消耗可能大于散列表，也就是说，位图不适合数据范围大，实际数据量小的问题。

这个时候就需要布隆过滤器进行优化，布隆过滤器是对位图的一种改进。在上述例子的基础上，保持位图大小不变，对数据范围的所有数据使用哈希函数进行处理，使他落在这个位图的范围内，这样就不必再开辟空间。

具体的做法是，对某一个数组使用多个哈希函数求值，每个值对应的位都置位true，也就是用k个bit表示一个数的存在。当查询时，同样用之前的多个哈希函数求值，对应的每一位都为true时，代表该数字存在。

以上的做法降低了哈希函数的冲突几率，但可能存在误判，如果经过计算，某个值存在，那么可能这个值不存在，但是如果经过计算后某个值不存在，则这个值一定不存在。

通过调整哈希函数个数、位图大小与存储数据的个数之间的比例，可以降低发生误判的概率。对于无法预知未来数据情况时，可以引入自动扩容机制。

### 3.4 朴素贝叶斯（Naive Bayesian）

#### 基本概念

朴素贝叶斯算法是一种概率统计算法。

基本公式：P（A｜B）=P（B｜A）*P（A）/P（B），意思是在B发生的前提下A发生的概率，等于在A发生的前提下B发生的概率乘以A发生的概率除以B发生的概率。

在包含复杂条件，无法取得P（B｜A）时，可以将P（B｜A）以独立条件为单位进一步分解，配合P（M * N）=P（M）* P（N）公式进行计算。

在p（B）无法取得的情况下，可以先对P（A）进行取否，计算P（A｜B）的反向概率，再对P（A｜B）的正向概率和反向概率进行相除，此时P（B）在计算过程中被约掉，我们再将正向与反向概率的比值作为判断的参考。

### 3.5 欧几里得距离（Euclidean distance）

#### 基本概念

欧几里得距离（Euclidean distance）是用来计算两个向量（Vector）之间的距离的。

欧几里得距离可以用来实现推荐系统。

### 3.6 B+树（B+ Tree）

#### 基本概念

B+树一种M叉树，树中的节点不存储数据，只作为索引，数据作为叶子节点串在一条链表上。

除根节点外，每个节点的子节点数不超过M个，不小于M/2个，根节点的字节点数不超过M/2个。

一般根节点会被存储在内存中，其他节点存储在磁盘中。

B+树可以用来实现MySQL数据库的索引，主要目的是方便按区间查找，减少索引占用的空间，以及减少磁盘I/O次数，其中M的值和操作系统的页大小相关。

### 3.7 启发式搜索算法（Heuristically Search Algorithm） 

#### 基本概念

A* 算法是对 Dijkstra 算法的优化和改造，属于启发式搜索算法（Heuristically Search Algorithm），它求得的路径不一定最短路径。

IDA* 算法、蚁群算法、遗传算法、模拟退火算法等也属于启发式搜索算法。

A*在Dijkstra的基础上，增加了启发函数（heuristic function）和估价函数（evaluation function）。其中启发函数一般选择曼哈顿距离（Manhattan distance），因为欧几里得距离涉及到比较复杂的开根号计算，曼哈顿距离的运算更高效。估价函数是对Dijkstra中的路径长度和启发函数的值求和。

A*和Dijkstra算法的结束条件不同，A *遍历到终点就结束，而Dijkstra需要在终点出队列之后才结束。



